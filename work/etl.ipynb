{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb4d2352-4f19-463e-a636-b92501406fad",
   "metadata": {},
   "source": [
    "# TEPEDELEN Léo DELLARICA Steven BARBIN Kevin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3c9a99-8d49-4b9e-b34e-4b254127ad08",
   "metadata": {},
   "source": [
    "# Projet EISI1 Capgemini MSPRTPRE813_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac20311-d226-41ef-a117-bb4e7c29091c",
   "metadata": {},
   "source": [
    "Ce notebook Python est le rapport détaillé et l'ETL de notre projet. La suite du rapport se situe après l'ETL, nous y détaillons le fonctionnement du reste du système."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a59e53-c647-4b41-aac5-9a9f88e3abb3",
   "metadata": {},
   "source": [
    "Il a été réalisé à l'aide de Docker afin d'en faciliter le déploiement pour tester et collaborer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0191696b-d940-4936-98d1-c92bc9e47e35",
   "metadata": {},
   "source": [
    "Vous trouverez tout ce qu'il vous faut pour essayer le programme sur votre machine dans le fichier README de ce repository github :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c88f7a-d9fd-4c32-a10d-3982d83f5b91",
   "metadata": {},
   "source": [
    "# Extraire les données dans un DataFrame pySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "984230eb-ee17-4ac4-b737-202c09251c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Créer une session Spark\n",
    "spark = SparkSession.builder.appName(\"example\") \\\n",
    "    .config(\"spark.dynamicAllocation.enabled\", \"true\") \\\n",
    "    .config(\"spark.dynamicAllocation.minExecutors\", \"1\") \\\n",
    "    .config(\"spark.dynamicAllocation.maxExecutors\", \"50\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .config(\"spark.executor.instances\", \"4\") \\\n",
    "    .config(\"spark.executor.cores\", \"2\") \\\n",
    "    .config(\"spark.memory.fraction\", \"0.8\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9e1c85a-64e5-4c3a-b22c-dc9951b32ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5251/2000495405.py:4: DtypeWarning: Columns (0,2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_demographie = pd.read_csv('https://www.dropbox.com/scl/fi/qayze0v5xxwolw4tj8qmc/popcommunes.csv.zip?rlkey=qnpfvfq0kc096dykwfvz2jrv0&st=gk60a3ff&dl=1', compression='zip', header=0, sep=',', quotechar='\"')\n",
      "/tmp/ipykernel_5251/2000495405.py:7: DtypeWarning: Columns (0,2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_csp = pd.read_csv('https://www.dropbox.com/scl/fi/opg91qcti1ctwmopr4efj/cspcommunes.csv.zip?rlkey=h8pti3tzoo7tqjctc2h1rfeqx&st=1mnddf1h&dl=1', compression='zip', header=0, sep=',', quotechar='\"')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# popcommunes.csv\n",
    "df_demographie = pd.read_csv('https://www.dropbox.com/scl/fi/qayze0v5xxwolw4tj8qmc/popcommunes.csv.zip?rlkey=qnpfvfq0kc096dykwfvz2jrv0&st=gk60a3ff&dl=1', compression='zip', header=0, sep=',', quotechar='\"')\n",
    "\n",
    "# cspcommunes.csv\n",
    "df_csp = pd.read_csv('https://www.dropbox.com/scl/fi/opg91qcti1ctwmopr4efj/cspcommunes.csv.zip?rlkey=h8pti3tzoo7tqjctc2h1rfeqx&st=1mnddf1h&dl=1', compression='zip', header=0, sep=',', quotechar='\"')\n",
    "\n",
    "# df_criminalite = pd.read_csv('https://drive.google.com/uc?export=download&id=1F9Jm0UaemicMy4MnvZ47nmZHiIdsmRwC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "806a6292-21e9-4295-b815-22fdb18d318d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_demographie.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b2ffbf8-b819-42cf-b7b0-8abd543aa048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using pandas\n",
    "\n",
    "df_demographie_filtre = df_demographie.filter(regex=\"^(dep|nomdep|codecommune|nomcommune|reg|nomreg)$|^pop[0-9]{4}$\")\n",
    "\n",
    "df_csp_filtre = df_csp.filter(regex=\"^(dep|nomdep|codecommune|nomcommune|agri|indp|cadr|pint|empl|ouvr|chom|pact|chom)(\\d{4})?$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55bc4ff0-4e9f-40d2-95d2-db3312e2c5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1. Create the dimension table for commune data (df_dimension_commune)\n",
    "# df_dimension_commune = df_demographie_filtre[['dep', 'codecommune', 'nomcommune', 'reg']].drop_duplicates()\n",
    "\n",
    "# # 2. Extract population columns (columns starting with \"pop\" followed by 4 digits)\n",
    "# pop_columns = [col for col in df_demographie_filtre.columns if col.startswith('pop') and len(col) == 7 and col[3:].isdigit()]\n",
    "\n",
    "# # 3. Pivot the population columns into long format for the facts table (df_faits)\n",
    "# # We use the `melt` function to transform wide to long format\n",
    "# df_faits = pd.melt(df_demographie_filtre, \n",
    "#                    id_vars=['codecommune'],  # Keep 'codecommune' as ID column\n",
    "#                    value_vars=pop_columns,   # These are the population columns to melt\n",
    "#                    var_name='annee',          # Name of the new 'annee' column\n",
    "#                    value_name='population')  # Name of the new 'population' column\n",
    "\n",
    "# # Extract annee from 'popXXXX' column\n",
    "# df_faits['annee'] = df_faits['annee'].str[-4:]\n",
    "\n",
    "# print(\"Dimension Commune Table:\")\n",
    "# print(df_dimension_commune)\n",
    "\n",
    "# print(\"\\nFacts Table (Population Data):\")\n",
    "# print(df_faits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506e6a3c-9d1a-4b9e-b138-17377c11201e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using pySpark\n",
    "\n",
    "df_demographie_filtre = spark.createDataFrame(df_demographie_filtre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c238b22-677c-41c2-8dd7-66a1748d9d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csp_filtre = spark.createDataFrame(df_csp_filtre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5ee84e-7c2a-415b-b3f4-42d7a2d0016a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3176f6b3-9a84-4dfa-9929-8ea9c543acb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Using pySpark\n",
    "\n",
    "\n",
    "# # 1. Create the dimension table for commune data (df_dimension_commune)\n",
    "# df_dimension_commune = df_demographie_filtre.select(\"dep\", \"codecommune\", 'nomcommune', \"reg\").distinct()\n",
    "\n",
    "# # 2. Extract population columns (columns starting with \"pop\" followed by 4 digits)\n",
    "# pop_columns = [col for col in df_demographie_filtre.columns if col.startswith('pop') and len(col) == 7 and col[3:].isdigit()]\n",
    "\n",
    "# # 3. Pivot the population columns into long format for the facts table (df_faits)\n",
    "# df_faits = df_demographie_filtre \\\n",
    "#     .withColumn(\"annee_population\", F.explode(F.array(\n",
    "#         *[F.struct(F.lit(col[-4:]).alias(\"annee\"), F.col(col).alias(\"population\")) for col in pop_columns]\n",
    "#     )))\n",
    "\n",
    "# # Split the \"annee_population\" struct into separate columns for annee and population\n",
    "# df_faits = df_faits.withColumn(\"annee\", F.col(\"annee_population.annee\")) \\\n",
    "#                    .withColumn(\"population\", F.col(\"annee_population.population\")) \\\n",
    "#                    .drop(\"annee_population\")\n",
    "\n",
    "# # 4. Join the facts table with the commune table to include commune_id in df_faits\n",
    "# df_faits = df_faits.select(\"codecommune\", \"annee\", \"population\")\n",
    "\n",
    "# # Display the results\n",
    "# df_dimension_commune.show()\n",
    "# df_faits.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec00ab57-b788-4e8d-8ca0-93ed1a9eb2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getColumnsWithStringAndFourDigits(str, df):\n",
    "    return [col for col in df.columns if col.startswith(str) and len(col) == len(str)+4 and col[-4:].isdigit()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae032c1-cee7-4def-af73-902edf1007e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # popcommunes\n",
    "\n",
    "# # 1. Optimize commune dimension table creation by dropping duplicates\n",
    "# df_dimension_commune = df_demographie_filtre.select(\"dep\", \"codecommune\", 'nomcommune', \"reg\").drop_duplicates()\n",
    "\n",
    "# # 2. Extract population columns (columns starting with \"pop\" followed by 4 digits)\n",
    "# pop_columns = getColumnsWithStringAndFourDigits(\"pop\", df_demographie_filtre)\n",
    "\n",
    "# # 3. Use stack() to pivot the population columns more efficiently for large datasets\n",
    "# df_faits = df_demographie_filtre.select(\"codecommune\", \n",
    "#                                         F.expr(\"stack({0}, {1})\".format(\n",
    "#                                             len(pop_columns),\n",
    "#                                             ','.join([f\"'{col[-4:]}', {col}\" for col in pop_columns])\n",
    "#                                         )).alias(\"annee\", \"population\"))\n",
    "\n",
    "# # Display the results\n",
    "# # df_dimension_commune.show()\n",
    "# # df_faits.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77e726f-7dd7-471e-8b06-593881aa9fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cspcommunes\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "# 1. Optimize commune dimension table creation by dropping duplicates\n",
    "df_dimension_commune = df_demographie_filtre.select(\"dep\",\"nomdep\", \"codecommune\", 'nomcommune', \"reg\", \"nomreg\").join(\n",
    "                        df_csp_filtre.select(\"dep\",\"nomdep\", \"codecommune\", 'nomcommune'), on=[\"dep\", \"codecommune\", \"nomdep\", 'nomcommune'], how=\"outer\").drop_duplicates().dropna(subset=[\"reg\", \"nomreg\"]).cache()\n",
    "\n",
    "# 2. Extract population columns (columns starting with \"pop\" followed by 4 digits)\n",
    "pop_columns = getColumnsWithStringAndFourDigits(\"pop\", df_demographie_filtre)\n",
    "\n",
    "csp_columns = OrderedDict()\n",
    "for str in [\"agri\",\"indp\",\"cadr\",\"pint\",\"empl\",\"ouvr\",\"chom\",\"pact\", \"chom\"]:\n",
    "    csp_columns[str] = getColumnsWithStringAndFourDigits(str, df_csp_filtre)\n",
    "\n",
    "annees_csp = OrderedDict()\n",
    "for key, col_list in csp_columns.items():\n",
    "    for col_name in col_list:\n",
    "        annees_csp.setdefault(col_name[-4:], []).append(col_name) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cc8c19-59db-4a51-9129-80beeddaf413",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# 3. Use stack() to pivot the population columns more efficiently for large datasets\n",
    "df_faits_population = df_demographie_filtre.select(\"codecommune\", F.expr(\"stack({0}, {1})\".format(\n",
    "                                                        len(pop_columns), ','.join([f\"'{col[-4:]}', {col}\" for col in pop_columns])\n",
    "                                        )).alias(\"annee\", \"population\"))\n",
    "\n",
    "\n",
    "cast=\"CAST(\"\n",
    "as_double=\" AS DOUBLE)\"\n",
    "\n",
    "df_faits_csp = df_csp_filtre.select(\"codecommune\", \n",
    "                                F.expr(\"stack({0}, {1})\".format(len(annees_csp),\n",
    "                                ','.join([f\"'{annee}', {', '.join([cast + s + as_double for s in col_name])}\" for annee, col_name in annees_csp.items()])\n",
    "                                )).alias(\"annee\", \"agriculteurs\", \"independants\", \"cadres\", \"intermediaires\", \"employes\", \"ouvriers\", \"population_active_totale\", \"chomeurs\"))\n",
    "\n",
    "# df_faits = df_faits_population.join(df_faits_csp, on=[\"codecommune\", \"annee\"], how=\"outer\")\n",
    "df_faits = df_faits_csp.join(df_faits_population, on=[\"codecommune\", \"annee\"], how=\"outer\").cache()\n",
    "\n",
    "# Display the results\n",
    "df_dimension_commune.count()\n",
    "df_faits.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b5c38e-a466-4672-bbc5-c51a86648914",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dimension_commune.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfeca07e-724a-450f-a566-69128070f105",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_faits.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c678588-2776-4004-a63b-d645cd9b5e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ','.join([f\"'{col[-4:]}', {col}\" for col in pop_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8075295-a4b9-4ec1-8c87-609eb144d77e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tentative infructueuse en utilisant pandas\n",
    "\n",
    "# df_faits = pd.DataFrame(columns=[\"population\"])\n",
    "# df_faits = spark.createDataFrame(df_faits)\n",
    "\n",
    "# df_dimension_commune = pd.DataFrame(columns=[\"code_departement\", \"code_commune\", \"code_region\"])\n",
    "# df_dimension_commune = spark.createDataFrame(df_dimension_commune)\n",
    "\n",
    "# df_dimension_annee = pd.DataFrame(columns=[\"annee\"])\n",
    "# df_dimension_annee = spark.createDataFrame(df_dimension_annee)\n",
    "\n",
    "# for idx, row in df_demographie_filtre.iterrows():\n",
    "#     df_dimension_commune.loc[len(df_dimension_commune)] = [row[\"dep\"], row[\"codecommune\"], row[\"reg\"]]\n",
    "#     for index, value in row.filter(regex=\"^pop[0-9]{4}$\").items():\n",
    "#         df_faits.loc[len(df_faits)] = [value]\n",
    "#         df_dimension_annee.loc[len(df_dimension_annee)] = [index[-4:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c02a34-5df3-41b9-bf0e-7dac5a401e0e",
   "metadata": {},
   "source": [
    "# Générer une table au format CSV avec une description statistique du DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c509e0fd-0c95-448d-b884-9b9ab7bfb6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.describe().toPandas().to_csv(\"describe_summary.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a5dbff-0230-4591-a711-21dc73918d26",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Effectuer un échantillonage du DataFrame pour en observer les colonnes qui peuvent sembler pertinentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d5f76d-d583-4802-9fa0-edc521eeb18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FRACTION_SIZE = 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d995a5-115b-42b1-a335-1ac1e7998960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columnsToSample = ['quantity', 'serving_size', 'serving_quantity', 'product_quantity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1ebc1d-f028-46f8-badf-46cc45681b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples_not_clean_df = df.select(columnsToSample).dropna(how='all').cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fe3f00-b57c-464f-a77c-b63e28e24461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples_df = samples_not_clean_df.sample(withReplacement=False, fraction=FRACTION_SIZE).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ab1de3-9d35-4cf7-a291-fc21f5c03a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdbd707-1f7a-43a5-89bf-2d0e1c650129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1fbeb1-073d-4f49-8d3b-5dcb68323199",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Extraire les valeurs uniques d'une colonne afin d'en confirmer la pertinence (colonne ingredients_analysis_tags en exemple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac11a35-ffa3-4555-9475-21774e8e3355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def flatten_list(li):\n",
    "#     flat_list = []\n",
    "#     for row in li:\n",
    "#         flat_list += row\n",
    "#     return flat_list\n",
    "\n",
    "# def make_list_unique(li):\n",
    "#     return list(dict.fromkeys(li))\n",
    "\n",
    "# def split_string_list_elements(li, sep):\n",
    "#     return [x.split(sep) for x in li]\n",
    "\n",
    "# def column_to_list(col):\n",
    "#     return col.rdd.flatMap(lambda x: x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f785cd80-da26-44c9-ad04-703fc19f1b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ingredients_analysis_list = make_list_unique(flatten_list(split_string_list_elements(column_to_list(df.select('ingredients_analysis_tags').dropna()), \",\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16092ba1-d5b4-44a1-884f-79649c1d1e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ingredients_analysis_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbea218f-d625-42e0-9bc9-c9905418c902",
   "metadata": {},
   "source": [
    "# Sélection des colonnes nécessaires après étude de celles-ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbddf06-6cc8-427d-b8ec-01b6724e754b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kept_columns = [\"code\", \"product_name\", \"product_quantity\", \"energy-kcal_100g\", \"fat_100g\", \"saturated-fat_100g\", \"monounsaturated-fat_100g\", \"polyunsaturated-fat_100g\", \"trans-fat_100g\", \n",
    "#                 \"carbohydrates_100g\", \"sugars_100g\", \"starch_100g\", \"fiber_100g\", \"proteins_100g\", \"allergens\", \"traces\", \"vitamin-a_100g\", \"vitamin-c_100g\", \"vitamin-d_100g\",\n",
    "#                 \"vitamin-e_100g\", \"vitamin-k_100g\", \"vitamin-b1_100g\", \"vitamin-b2_100g\", \"vitamin-b6_100g\", \"vitamin-b9_100g\", \"vitamin-b12_100g\", \"calcium_100g\",\n",
    "#                 \"iron_100g\", \"magnesium_100g\", \"potassium_100g\", \"zinc_100g\", \"food_groups_tags\", \"serving_size\", \"serving_quantity\", \"cholesterol_100g\", \"salt_100g\", \"glycemic-index_100g\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee5f531-00a6-4b91-b5a2-b96c156ac3f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_kept_columns = df.select(kept_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36aac7f-d961-4ad3-8a2e-b686e123db86",
   "metadata": {},
   "source": [
    "# Qualité des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5865a15b-462b-47e0-a0aa-58fcc3bde723",
   "metadata": {},
   "source": [
    "## On supprime les lignes qui ont moins de 15 colonnes très pertinentes non nulles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cff244-deab-4ecb-bb91-3f1c8aab0aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns_to_check = [\"code\", \"product_name\", \"product_quantity\", \"energy-kcal_100g\", \"fat_100g\", \"saturated-fat_100g\", \"monounsaturated-fat_100g\",\n",
    "#                     \"polyunsaturated-fat_100g\", \"trans-fat_100g\", \"carbohydrates_100g\", \"sugars_100g\", \"starch_100g\", \n",
    "#                     \"fiber_100g\", \"proteins_100g\", \"allergens\", \"traces\", \"food_groups_tags\", \"serving_size\", \"serving_quantity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654d9c42-65bb-45b0-8424-a6a4e46412f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_kept_columns = df_kept_columns.dropna(subset=columns_to_check, thresh=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80a219a-d79c-42ab-bbe8-690ac1e93ac4",
   "metadata": {},
   "source": [
    "## On supprime les lignes dupliquées et on garde le DF en cache pour éviter de le recalculer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbddb80b-ca7e-4fde-a846-3a061669a46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_kept_columns = df_kept_columns.dropDuplicates().cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232b7def-6aa5-4c8c-80d2-819edf14a7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Nombre de lignes restantes après le traitement : \" + str(df_kept_columns.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b975b69-adad-403a-9dab-a81f651c20e0",
   "metadata": {},
   "source": [
    "## Plus besoin du DataFrame de base donc on le retire de la mémoire cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67819e1e-1b25-4e4f-bc09-06af99ed72a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.unpersist()\n",
    "# print(\"Mémoire libérée\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81fa1d0-2f4a-4fc6-94a2-6b10cbf605ad",
   "metadata": {},
   "source": [
    "# Écriture des données nettoyées en base de données avec le driver JDBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2722c1f-7bb7-4414-bbc6-cb26c63d2896",
   "metadata": {},
   "outputs": [],
   "source": [
    "properties = {\n",
    "    \"user\": \"user\",\n",
    "    \"password\": \"userpassword\",\n",
    "    \"driver\": \"com.mysql.cj.jdbc.Driver\"\n",
    "}\n",
    "\n",
    "df_kept_columns.write.jdbc(url=\"jdbc:mysql://mysql:3306/openfoodfact\", table=\"products\", mode=\"append\", properties=properties)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
